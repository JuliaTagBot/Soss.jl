var documenterSearchIndex = {"docs":
[{"location":"misc/#Models-and-JointDistributions-1","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"","category":"section"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"A Model in Soss","category":"page"},{"location":"misc/#Model-Combinators-1","page":"Models and JointDistributions","title":"Model Combinators","text":"","category":"section"},{"location":"misc/#Building-Inference-Algorithms-1","page":"Models and JointDistributions","title":"Building Inference Algorithms","text":"","category":"section"},{"location":"misc/#Inference-Primitives-1","page":"Models and JointDistributions","title":"Inference Primitives","text":"","category":"section"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"At its core, Soss is about source code generation. Instances of this are referred to as inference primitives, or simply \"primitives\". As a general rule, new primitives are rarely needed. A wide variety of inference algorithms can be built using what's provided. ","category":"page"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"To easily find all available inference primitives, enter Soss.source<TAB> at a REPL. Currently this returns this result:","category":"page"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"julia> Soss.source\nsourceLogpdf         sourceRand            sourceXform\nsourceParticles      sourceWeightedSample","category":"page"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"The general pattern is that a primitive sourceFoo specifies how code is generated for an inference function foo. ","category":"page"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"For more details on inference primitives, see the Internals section.","category":"page"},{"location":"misc/#Inference-Functions-1","page":"Models and JointDistributions","title":"Inference Functions","text":"","category":"section"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"An inference function is a function that takes a JointDistribution as an argument, and calls at least one inference primitive (not necessarily directly). The wrapper around each primitive is a special case of this, but most inference functions work at a higher level of abstraction.","category":"page"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"There's some variability , but is often of the form","category":"page"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"foo(d::JointDistribution, data::NamedTuple)","category":"page"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"For example, advancedHMC uses TuringLang/AdvancedHMC.jl , which needs a logpdf and its gradient. ","category":"page"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"Most inference algorithms can be expressed in terms of inference primitives. ","category":"page"},{"location":"misc/#Chain-Combinators-1","page":"Models and JointDistributions","title":"Chain Combinators","text":"","category":"section"},{"location":"misc/#-1","page":"Models and JointDistributions","title":"","text":"","category":"section"},{"location":"misc/#-2","page":"Models and JointDistributions","title":"","text":"","category":"section"},{"location":"misc/#Internals-1","page":"Models and JointDistributions","title":"Internals","text":"","category":"section"},{"location":"misc/#Models-1","page":"Models and JointDistributions","title":"Models","text":"","category":"section"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"struct Model{A,B}\n    args  :: Vector{Symbol}\n    vals  :: NamedTuple\n    dists :: NamedTuple\n    retn  :: Union{Nothing, Symbol, Expr}\nend","category":"page"},{"location":"misc/#","page":"Models and JointDistributions","title":"Models and JointDistributions","text":"function sourceWeightedSample(_data)\n    function(_m::Model)\n\n        _datakeys = getntkeys(_data)\n        proc(_m, st :: Assign)     = :($(st.x) = $(st.rhs))\n        proc(_m, st :: Return)     = nothing\n        proc(_m, st :: LineNumber) = nothing\n\n        function proc(_m, st :: Sample)\n            st.x ∈ _datakeys && return :(_ℓ += logpdf($(st.rhs), $(st.x)))\n            return :($(st.x) = rand($(st.rhs)))\n        end\n\n        vals = map(x -> Expr(:(=), x,x),variables(_m)) \n\n        wrap(kernel) = @q begin\n            _ℓ = 0.0\n            $kernel\n            \n            return (_ℓ, $(Expr(:tuple, vals...)))\n        end\n\n        buildSource(_m, proc, wrap) |> flatten\n    end\nend\n","category":"page"},{"location":"misc/#-3","page":"Models and JointDistributions","title":"","text":"","category":"section"},{"location":"#Soss.jl-1","page":"Home","title":"Soss.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Modules = [Soss]","category":"page"},{"location":"#Soss.MarkovChain","page":"Home","title":"Soss.MarkovChain","text":"MarkovChain\n\nMarkovChain(pars, step) defines a Markov Chain with global parameters pars and transition kernel step. Here, pars is a named tuple, and step is a Soss model that takes arguments (pars, state) and returns a next value containing the new pars and state.\n\nNOTE: This is experimental, and may change in the near future.\n\nmstep = @model pars,state begin\n    σ = pars.σ\n    x0 = state.x\n    x ~ Normal(x0, σ)\n    next = (pars=pars, state=(x=x,))\nend;\n\nm = @model s0 begin\n    σ ~ Exponential()\n    pars = (σ=σ,)\n    chain ~ MarkovChain(pars, mstep(pars=pars, state=s0))\nend;\n\nr = rand(m(s0=(x=2,),));\n\nfor s in Iterators.take(r.chain,3)\n    println(s)\nend\n\n\n\n\n\n","category":"type"},{"location":"#Soss.prior-Tuple{Model,Vararg{Any,N} where N}","page":"Home","title":"Soss.prior","text":"prior(m, xs...)\n\nReturns the minimal model required to sample random variables xs.... Useful for extracting a prior distribution from a joint model m by designating xs... and the variables they depend on as the prior and hyperpriors.\n\nExample\n\nm = @model n begin\n    α ~ Gamma()\n    β ~ Gamma()\n    θ ~ Beta(α,β)\n    x ~ Binomial(n, θ)\nend;\nprior(m, :θ)\n\n# output\n@model begin\n        β ~ Gamma()\n        α ~ Gamma()\n        θ ~ Beta(α, β)\n    end\n\n\n\n\n\n","category":"method"},{"location":"#Soss.prune-Tuple{Model,Vararg{Symbol,N} where N}","page":"Home","title":"Soss.prune","text":"prune(m, xs...; trim_args = true)\n\nReturns a model transformed by removing xs... and all variables that depend on xs.... If trim_args = true, unneeded arguments are also removed. Use trim_args = false to leave arguments unaffected.\n\nExamples\n\nm = @model n begin\n    α ~ Gamma()\n    β ~ Gamma()\n    θ ~ Beta(α,β)\n    x ~ Binomial(n, θ)\nend;\nprune(m, :θ)\n\n# output\n@model begin\n        β ~ Gamma()\n        α ~ Gamma()\n    end\n\nm = @model n begin\n    α ~ Gamma()\n    β ~ Gamma()\n    θ ~ Beta(α,β)\n    x ~ Binomial(n, θ)\nend;\nprune(m, :n)\n\n# output\n@model begin\n        β ~ Gamma()\n        α ~ Gamma()\n        θ ~ Beta(α, β)\n    end\n\n\n\n\n\n","category":"method"},{"location":"#Soss.PySymPyModule","page":"Home","title":"Soss.PySymPyModule","text":"As type encoding a PyObject is unsafe without some hard works with reference counting, we simply use a Julia proxy to imitate the sympy module, e.g.,     sympy.attr = _pysympy.attr\n\n\n\n\n\n","category":"type"}]
}
